{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86894925-952f-4b4c-9cf4-188febd1695c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "churn1 = pd.read_csv('churn_manipulate_data_for_ML.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e4f4f7-bfa1-492a-8f1e-caceec640ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "churn1= churn1.drop(['totalcharges'], axis =1)\n",
    "churn1=  churn1.drop(['Unnamed: 0'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a986fa-820c-49d2-a975-6fbdf16650d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the library\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Train and split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "test_size = 0.2\n",
    "train, test = train_test_split(churn1, test_size=0.2, random_state=0, shuffle=True)\n",
    "\n",
    "label = 'churn'\n",
    "\n",
    "x_train = train.drop(label, axis=1)\n",
    "#x_train = preprocessing.normalize(x_train, norm='l2')\n",
    "\n",
    "y_train = train[label]\n",
    "\n",
    "x_test = test.drop(label, axis=1)\n",
    "#x_test = preprocessing.normalize(x_test, norm='l2')\n",
    "y_test = test[label]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3589086f-caef-451d-ba87-e755448a59ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier # Importing the algorithm\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=4)\n",
    "# define the algorithm:\n",
    "    # arg:\n",
    "        # max_depth = The maximum depth of the tree. (If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples)\n",
    "\n",
    "\n",
    "clf.fit(x_train, y_train) # running\\training the algorithm with the train data\n",
    "\n",
    "y_test_pred_DecisionTree = clf.predict(x_test) # making a prediction based on \"test\" data features\n",
    "\n",
    "\n",
    "output = pd.DataFrame({ 'what_actualy_happened':y_test, 'predicted_by_model': y_test_pred_DecisionTree}) # saving results to DataFrame\n",
    "output.to_csv('churn_DecisionTree_Prediction.csv', index=False) # saving results to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def0b75b",
   "metadata": {},
   "source": [
    "#output\n",
    "x_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f06c15f-0815-49cf-9ab2-a3460812a1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "# Evaluation for Decision Tree\n",
    "test_acc = accuracy_score(y_test, y_test_pred_DecisionTree)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a49ac6-f394-442e-905a-3c16ceb4a06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the decision tree\n",
    "# Importing the necessary libraries\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from IPython.display import SVG\n",
    "from graphviz import Source\n",
    "from IPython.display import display\n",
    "\n",
    "# this is afunction that we can always use for plotting decision trees, the function expects 3 arg as follows\n",
    "def plot_tree(tree, features, labels):\n",
    "    graph = Source(export_graphviz(tree, feature_names=features, class_names=labels, filled = True))\n",
    "    display(SVG(graph.pipe(format='svg')))\n",
    "\n",
    "# Using the function above, with the 3 arg\n",
    "    # tree\n",
    "    # feaures\n",
    "    # labels --> we'll go over the example and it will be clear\n",
    "plot_tree(clf, x_train.columns, ['churn', 'not_churn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bb3cb9-119d-4812-b28e-b18e837b7fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier # Importing the algorithm\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=450, max_depth=9, random_state=1)\n",
    "# define the algorithm:\n",
    "    # arg:\n",
    "        # n_estimators = number of trees\n",
    "        # max_dept = the maximum depth of the trees\n",
    "        # random_state =\n",
    "            # basically, an algorithm is repeated a number of times using random selections of features and samples. The random_state parameter allows controlling these random choices.\n",
    "            # if you call this with random_state=1 (or any other value), then each and every time, you'll get the same result.\n",
    "            \n",
    "rf.fit(x_train, y_train) # running\\training the algorithm with the train data\n",
    "\n",
    "y_test_pred_RandomForest = rf.predict(x_test) # making a prediction based on \"test\" data features\n",
    "\n",
    "\n",
    "output = pd.DataFrame({'what_actualy_happened':y_test, 'predicted_by_model': y_test_pred_RandomForest}) # saving results to DataFrame\n",
    "output.to_csv('my_RandomForest_Prediction.csv', index=False) # saving results to csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80314b60-fe34-41e2-a038-b6b338d9face",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "# RandomForestClassifier\n",
    "test_acc = accuracy_score(y_test, y_test_pred_RandomForest)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6f27ad-eca5-4a34-a140-8aabc3f1fdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "start_time = time.time()\n",
    "importances = rf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"Elapsed time to compute the importances: {elapsed_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8391c143-8c39-43f5-88a7-034e5ce2493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [f\"feature {i}\" for i in range(x_train.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeb45eb-e107-4eef-bfa1-79e5b0c60924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "forest_importances=rf.feature_importances_\n",
    "forest_importances = pd.Series(importances, index=feature_names)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c3794b-90d7-495f-a98c-698a41ebdb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= forest_importances.sort_values()[30:51]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b8f227-574f-4ca9-9c80-7eb59f30b558",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len( forest_importances)):\n",
    "    print(i,x_train.columns[i],forest_importances[i] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d8c49a-60b6-4370-89bb-49ea6da2bacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier  # Importing the algorithm\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=15)\n",
    "# define the algorithm:\n",
    "    # arg:\n",
    "        # n_neighbors = number of neighbors\n",
    "        \n",
    "knn.fit(x_train, y_train) # running\\training the algorithm with the train data\n",
    "\n",
    "y_test_pred_Knn = knn.predict(x_test) # making a prediction based on \"test\" data features\n",
    "\n",
    "output = pd.DataFrame({'what_actualy_happened':y_test, 'predicted_by_model': y_test_pred_Knn}) # saving results to DataFrame\n",
    "output.to_csv('my_Knn_Prediction.csv', index=False) # saving results to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd21115-f508-4a19-8548-8236c378260d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "# Evaluation for KNeighborsClassifier\n",
    "test_acc = accuracy_score(y_test, y_test_pred_Knn)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db11ddd2-525b-4cea-ae10-9f38116e1ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression  # Importing the algorithm\n",
    "\n",
    "logReg = LogisticRegression(solver = 'lbfgs',max_iter= 550)#max_iter= 3000\n",
    "#logisticRegr = LogisticRegression(solver = 'lbfgs')\n",
    "        \n",
    "logReg.fit(x_train, y_train) # running\\training the algorithm with the train data\n",
    "\n",
    "y_test_pred_logReg = logReg.predict(x_test) # making a prediction based on \"test\" data features\n",
    "\n",
    "output = pd.DataFrame({'what_actualy_happened':y_test, 'predicted_by_model': y_test_pred_logReg}) # saving results to DataFrame\n",
    "output.to_csv('my_Knn_Prediction.csv', index=False) # saving results to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fe518c-f911-437d-868e-326002ea08e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation for LogisticRegression\n",
    "test_acc = accuracy_score(y_test, y_test_pred_logReg)\n",
    "test_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
